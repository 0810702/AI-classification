{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR10_CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPsbHqkEJYcajk1gYZ4+HsR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sQLZ1DBBBli2"},"outputs":[],"source":["class CIFAR_CNN():\n","  def __init__(self, x, y):\n","    self.x_train, self.y_train, self.x_valid, self.y_valid = self.Split_Dataset(x, y)\n","    self.model = self.CIFAR_Model()\n","  \n","  # splid data into training and validation set\n","  def Split_Dataset(self, x, y):\n","    # random shuffle\n","    index = np.arange(x.shape[0]) # create an integer list from 0 ~ t_len\n","    np.random.shuffle(index)\n","    x = x[index]\n","    y = y[index]\n","\n","    # seperate temp set to training and validation set\n","    total_length = x.shape[0]\n","    training_length = int(x.shape[0]*0.9)\n","    x_train = x[:training_length]\n","    y_train = y[:training_length]\n","    x_valid = x[training_length:total_length]\n","    y_valid = y[training_length:total_length]\n","\n","    return x_train, y_train, x_valid, y_valid\n","\n","  # construct CNN model for CIFAR-10\n","  def CIFAR_Model(self, output_size=10):\n","    # model construction\n","    model = Sequential()\n","\n","    # first layer (conv), input_shape=(32, 32, 3)\n","    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n","    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n","    model.add(MaxPooling2D(pool_size = (2,2)))\n","\n","    # second layer (conv)\n","    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n","    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n","    model.add(MaxPooling2D(pool_size = (2,2)))\n","    \n","    # third layer (conv)\n","    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n","    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n","    model.add(MaxPooling2D(pool_size = (2,2)))\n","    model.add(Flatten())\n","    \n","    # fourth layer (fully)\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dropout(0.2))\n","\n","    # output layer (fully)\n","    model.add(Dense(output_size, activation='softmax'))\n","    \n","    # compile model\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    \n","    return model\n","  \n","  # training process\n","  def Training(self, epoch=50):\n","    self.history = self.model.fit(self.x_train, self.y_train, epochs=epoch, batch_size=32, validation_data=(self.x_valid, self.y_valid))\n","\n","  # plot learning information\n","  def Plot(self):\n","    # plot learning curve\n","    plt.plot(self.history.history['loss'], color='blue', label='training loss')\n","    plt.title('Learning Curve')\n","    plt.xlabel('epochs')\n","    plt.ylabel('cross-entropy loss')\n","    plt.legend()\n","    plt.show()\n","\n","    plt.plot(self.history.history['accuracy'], color='blue', label='training accuracy')\n","    plt.plot(self.history.history['val_accuracy'], color='red', label='validation accuracy')\n","    plt.title('Accuracy')\n","    plt.xlabel('epochs')\n","    plt.ylabel('Accuracy rate')\n","    plt.legend()\n","    plt.show()"]}]}